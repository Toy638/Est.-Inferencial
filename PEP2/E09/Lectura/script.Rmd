---
title: "script"
author: "Franco Salvo"
date: "2023-11-23"
output: html_document
---


Script 12.1: ajuste de una regresión lineal simple.
```{r}

# Cargar la biblioteca ggpubr
library(ggpubr)

# Cargar los datos
datos <- mtcars

# Ajustar el modelo con R
modelo <- lm(mpg ~ wt, data = datos)
print(summary(modelo))

# Graficar el modelo
p <- ggscatter(datos, x = "wt", y = "mpg", color = "blue", fill = "blue", xlab = "Peso [lb x 1000]", ylab = "Rendimiento [millas/galón]")
p <- p + geom_smooth(method = lm, se = FALSE, colour = "red")
print(p)

# Crear gráficos para evaluar el modelo
plot(modelo)

# Ingresar algunas instancias artificiales
mpg <- c(23.714, 19.691, 19.242, 12.430, 10.090, 9.565, 18.171, 26.492, 7.054, 24.447, 15.683, 17.403, 13.465, 18.850, 29.493)
wt <- c(2.973, 4.532, 2.332, 3.016, 4.220, 4.286, 2.580, 3.084, 3.816, 2.775, 3.251, 3.013, 4.951, 2.644, 2.218)

nuevos <- data.frame(mpg, wt)

# Usar el modelo para predecir el rendimiento de los nuevos y ver los residuos resultantes
predicciones <- predict(modelo, nuevos)
residuos <- nuevos$mpg - predicciones
nuevos <- data.frame(nuevos, residuos)

# Crear un gráfico de dispersión de residuos
r <- ggscatter(nuevos, x = "wt", y = "residuos", color = "blue", fill = "blue", xlab = "Peso [lb * 1000]", ylab = "Residuo")
r <- r + geom_hline(yintercept = 0, colour = "red")
print(r)


```

Script 12.2: reemplazar una variable dicotómica por una variable indicadora.

```{r}
# Crear un data frame con una variable dicotómica. 
alumno <- 1:5
sexo <- factor(c("F", "M", "F","F", "M")) 
datos <- data.frame(alumno , sexo)

# Crear una variable indicadora para sexo , con valor 0 para hombres y 1, para mujeres. 
es_mujer <- rep(1, length(sexo)) 
es_mujer[sexo == "M"] <- 0

# Reemplazar la variable sexo por lavariable indicadora.
datos <- cbind(datos , es_mujer)
datos[["sexo"]] <- NULL

```

Script 12.3: alternativa robusta para comparar entre múltiples grupos correlacionados.

```{r}
library(ggpubr)
# Cargar los datos. 
datos <- mtcars

# Ajustar el modelo con R
modelo <- lm(mpg ~ vs, data = datos)
print(summary(modelo))

# Graficar el modelo
p <- ggscatter(datos, x = "vs", y = "mpg", color = "blue", fill = "blue", xlab = "Forma del motor", ylab = "Rendimiento [millas/galón]", xticks.by = 1)
p <- p + geom_smooth(method = lm, se = FALSE, colour = "red")
print(p)

# Crear gráficos para evaluar el modelo
plot(modelo)

# Graficar residuos
residuos <- modelo$residuals
datos <- cbind(datos, residuos)
datos[["vs"]] <- factor(datos[["vs"]])

r <- ggqqplot(datos , x = "residuos",
              facet.by = "vs", color = "vs",
              palette = c("blue", "red"))
print(r)

```

Script 12.4: ajuste de una regresión lineal simple usando validación cruzada.

```{r}


# Cargar los datos
datos <- mtcars

# Crear conjuntos de entrenamiento y prueba
set.seed(101)
n <- nrow(datos)
n_entrenamiento <- floor(0.7 * n)
muestra <- sample.int(n = n, size = n_entrenamiento, replace = FALSE)
entrenamiento <- datos[muestra, ]
prueba <- datos[-muestra, ]

# Ajustar el modelo con el conjunto de entrenamiento
modelo <- lm(mpg ~ wt, data = entrenamiento)
print(summary(modelo))

# Calcular el error cuadrado promedio para el conjunto de entrenamiento
mse_entrenamiento <- mean(modelo$residuals ** 2)
cat("MSE para el conjunto de entrenamiento:", mse_entrenamiento, "\n")

# Hacer predicciones para el conjunto de prueba
predicciones <- predict(modelo, prueba)

# Calcular el error cuadrado promedio para el conjunto de prueba
error <- prueba[["mpg"]] - predicciones
mse_prueba <- mean(error ** 2)
cat("MSE para el conjunto de prueba:", mse_prueba)




```

Script 12.5: ajuste de una regresión lineal simple usando validación cruzada de 5 pliegues

```{r}

library(caret)

# Cargar los datos
datos <- mtcars

# Crear conjuntos de entrenamiento y prueba
set.seed(101)
n <- nrow(datos)
n_entrenamiento <- floor(0.7 * n)
muestra <- sample.int(n = n, size = n_entrenamiento, replace = FALSE)
entrenamiento <- datos[muestra, ]
prueba <- datos[-muestra, ]

# Ajustar el modelo con el conjunto de entrenamiento
modelo <- lm(mpg ~ wt, data = entrenamiento)
print(summary(modelo))

# Calcular el error cuadrado promedio para el conjunto de entrenamiento
mse_entrenamiento <- mean(modelo$residuals ** 2)
cat("MSE para el conjunto de entrenamiento:", mse_entrenamiento, "\n")

# Hacer predicciones para el conjunto de prueba
predicciones <- predict(modelo, prueba)

# Calcular el error cuadrado promedio para el conjunto de prueba
error <- prueba[["mpg"]] - predicciones
mse_prueba <- mean(error ** 2)
cat("MSE para el conjunto de prueba:", mse_prueba)



```


Script 12.6: regresión lineal para la cantidad de requisitos funcionales de acuerdo a la cantidad de stakeholders.


```{r}
library(ggpubr)

# Crear los datos originales.
requisitos <- c(11, 10, 12, 14, 8, 13, 18, 15, 20, 16, 21, 13, 10, 9, 21)
stakeholders <- c(8, 8, 6, 6, 8, 7, 3, 1, 3, 4, 5, 4, 4, 9, 2)
datos <- data.frame(requisitos, stakeholders)

# Ajustar modelo.
modelo <- lm(requisitos ~ stakeholders, data = datos)
print(summary(modelo))

# Graficar el modelo.
p <- ggscatter(
  datos, x = "stakeholders", y = "requisitos", color = "blue", fill = "blue",
  xlab = "Stakeholders", ylab = "Requisitos funcionales"
)
p <- p + geom_smooth(method = lm, se = FALSE, colour = "red")

# Graficar los residuos.
b_1 <- modelo$coefficients[2]
b_0 <- modelo$coefficients[1]
residuos <- datos[["requisitos"]] - (b_1 * datos[["stakeholders"]] + b_0)
datos <- data.frame(datos, residuos)

r <- ggscatter(
  datos, x = "stakeholders", y = "residuos", color = "blue",
  fill = "blue", xlab = "Stakeholders", ylab = "Residuo"
)
r <- r + geom_hline(yintercept = 0, colour = "red")

g <- ggarrange(p, r, ncol = 2, nrow = 1)
print(g)

# Verificar normalidad de los residuos.
cat("Prueba de normalidad para los residuos\n")
print(shapiro.test(datos$residuos))

```



