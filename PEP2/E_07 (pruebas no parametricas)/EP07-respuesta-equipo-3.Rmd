---
title: "EP07-respuesta-equipo-3"
output: html_document
date: "2023-10-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggpubr)
library(gridExtra)
```

### **Pregunta 1**

**Observando los datos, la memorista sospecha que hay diferencias significativas en el tiempo de ejecución entre las versiones A y C del algoritmo cuando las instancias tienen 60 o más nodos. ¿Los datos respaldan la intuición de la memorista? Para responder, filtren los datos para tener las instancias con 60 o más nodos y seleccionen las columnas de los tiempos de ejecución de las versiones A y C en formato ancho. Usando como semilla el valor 73, obtenga muestras aleatorias independientes de 24 tiempos registrados por la versión A y 20 tiempos registrados por la versión C del algoritmo. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.**

Hipotesis:

- H0: No hay diferencias significativas en el tiempo de ejecución entre las versiones A y C del algoritmo cuando las instancias tienen 60 o más nodos.

- HA: Hay diferenencias significativas en el tiempo de ejecución entre las versiones A y C del algoritmo cuando las instancias tienen 60 o más nodos.
```{r}
set.seed(73)

datos <- read.csv2("EP07 Datos.csv", sep = ",")

instancia <- 1:150
algA <- datos$tiempo.A[datos$n.nodos >= 60]
algC <- datos$tiempo.C[datos$n.nodos >= 60]

tiempos <- data.frame(instancia, algA, algC)

indicesA <- sample(instancia, 24)
#Se utiliza setdiff para asegurar la independencia en el muestreo
indicesC <- sample(as.integer(setdiff(instancia, indicesA)), 20)

muestraA <- tiempos$algA[indicesA]
muestraC <- tiempos$algC[indicesC]

# Crear los gráficos Q-Q plot
qqplot_A <- ggqqplot(muestraA, main="A")
qqplot_C <- ggqqplot(muestraC, main="C")

# Organizar los gráficos en una sola fila
grid.arrange(qqplot_A, qqplot_C, nrow=1)

```

Como se puede apreciar, el gráfico de la muestraA, posee valores atípicos, por lo que no se cumple del todo la condición de la distribución normal de la prueba t. En consecuencia, se hará uso de una prueba no paramétrica con variables numéricas. Como se está trabajando con muestras independientes, se utilizará la prueba de suma de rangos de Wilcoxon.

Para trabajar con la prueba de suma de rangos de Wilcoxon, se deben verificar las siguientes condiciones:

1- Las observaciones de ambas muestras son independientes.

2- La escala de medición empleada debe ser a lo menos ordinal, de modo que tenga sentido hablar de
relaciones de orden (“igual que”, “menor que”, “mayor o igual que”).

La primera condición se cumple, puesto que ambas muestras son independientes entre sí.

Trabajando con mediciones de tiempo en milisegundos, se puede afirmar que la escala de medición es a lo menos ordinal, ya que los valores se pueden ordenar y es lógico establecer relaciones de orden. Esto se debe a que se puede comparar los valores de tiempo y determinar que, por ejemplo, 1 milisegundo es menor que 100 milisegundos.

Ahora, se procede a trabajar con la prueba de suma de rangos de Wilcoxon.

```{r}
alfa <- 0.05

# Hacer la prueba de Mann - Whitney .
prueba <- wilcox.test(muestraA,muestraC,alternative = "two.sided" , conf.level = 1 - alfa)
print(prueba)
```

Como el p-value es mayor al nivel de significancia establecido, se falla al rechazar la hipótesis nula. Por lo tanto, con un 95% de confianza, se puede inferir que no hay prueba suficiente para respaldar la intuición de la memorista.

### **Pregunta 2**

**La memorista también sospecha que, al comparar las mismas instancias de iguales características, las mejores soluciones encontradas por las versiones A y B tienen rendimientos distintos. ¿Estará en lo cierto? Para responder, filtren los datos para tener las instancias con 60 o más nodos y seleccionen las columnas con el mejor rendimiento de las versiones A y B en formato ancho. Usando como semilla el valor 13, obtengan una muestra aleatoria de 22 instancias. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.**

Hipótesis:

- H0: Para las mismas instancias no existe diferencia significativa en el rendimiento de la mejores soluciones encontradas para las versiones A y B del algoritmo cuando las instancias tienen 60 o más nodos.

- HA: Para las mismas instancias existe diferencia significativa en el rendimiento de la mejores soluciones encontradas para las versiones A y B del algoritmo cuando las instancias tienen 60 o más nodos.

```{r}

set.seed(13)

algAmejor <- datos$mejor.A[datos$n.nodos >= 60]
algBmejor <- datos$mejor.B[datos$n.nodos >= 60]

mejor_rendimiento <- data.frame(instancia, algAmejor, algBmejor)  

indiceMejor <- sample(instancia, 22)

muestraAmejor <- as.double(mejor_rendimiento$algAmejor[indiceMejor])
muestraBmejor <- as.double(mejor_rendimiento$algBmejor[indiceMejor])

# Crear los gráficos Q-Q plot
qqplot_A <- ggqqplot(muestraAmejor, main="A")
qqplot_B <- ggqqplot(muestraBmejor, main="B")

# Organizar los gráficos en una sola fila
grid.arrange(qqplot_A, qqplot_B, nrow=1)

```

Como se puede apreciar,los gráficos poseen valores atípicos, por lo que no se cumple la condición de la distribución normal de la prueba t. En consecuencia, se hará uso de una prueba no paramétrica con variables numéricas. Como se está trabajando con muestras pareadas, se utilizará la prueba de rangos con signo de Wilcoxon.

Para trabajar con la prueba de rangos con signo de Wilcoxon, se deben verificar las siguientes condiciones:

1- Los pares de observaciones son independientes.
2- La escala de medición empleada para las observaciones es intrínsecamente continua.
3- La escala de medición empleada para ambas muestras debe ser a lo menos ordinal.

Para la primera condición, puesto que cada par pertenece a instancias distintas, los pares de observaciones son independientes.

Para la segunda condición, se puede confirmar debido a que se está trabajando con porcentajes y estos resultan ser una escala de medición intrínsecamente continua.

Para la tercera condición, como se está trabajando con mediciones de porcentajes, se puede afirmar que la escala de medición es a lo menos ordinal, ya que los valores se pueden ordenar y es lógico establecer relaciones de orden. Esto se debe a que se puede comparar los valores y determinar que, por ejemplo, 10% es menor que 90%.

Ahora, se procede a trabajar con la prueba de rangos con signo de Wilcoxon.

```{r}
alfa <- 0.05
# Hacer la prueba de rangos con signo de Wilcoxon .
prueba <- wilcox.test(muestraAmejor,muestraBmejor,alternative = "two.sided",paired = TRUE,conf.level = 1 - alfa )
print(prueba)
```

Puesto que el p-value es inferior al nivel de significancia establecido, se rechaza la hipótesis nula a favor de la hipótesis alternativa. Por lo tanto, con un 95% de confianza, se puede inferir que las mejores soluciones encontradas por las versiones A y B tienen rendimientos distintos.

### **Pregunta 3**
**La memorista sospecha que hay diferencias significativas en el tiempo de ejecución entre las versiones del algoritmo cuando las instancias de prueba tienen 50 o más nodos. ¿Los datos respaldan la intuición de la memorista?**
**Para responder, filtren los datos para tener las instancias con 50 o más nodos y seleccionen las columnas con los tiempos de ejecución registrados (en formato ancho). Usando como semilla el valor 43, obtengan muestras aleatorias independientes de 15, 15 y 13 tiempos registrados por las versiones A, B y C, respectivamente. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.**

Hipótesis:

- H0: No hay diferenencias significativas en el tiempo de ejecución entre las versiones A, B y C del algoritmo cuando las instancias tienen 50 o más nodos, es decir, todos los algoritmos son igual de eficientes.

- HA: Hay diferenencias significativas en el tiempo de ejecución entre las versiones A, B y C del algoritmo cuando las instancias tienen 50 o más nodos, es decir, al menos uno de los algoritmos presenta una eficiencia diferente a al menos algún otro algoritmo.

```{r}
instancia <- 1:170
algA <- datos$tiempo.A[datos$n.nodos >= 50]
algB <- datos$tiempo.B[datos$n.nodos >= 50]
algC <- datos$tiempo.C[datos$n.nodos >= 50]

tiempos <- data.frame(instancia, algA, algB, algC)

set.seed(43)

indicesA <- sample(instancia, 15)
#Se utiliza setdiff para asegurar la independencia en el muestreo
indicesB <- sample(as.integer(setdiff(instancia, indicesA)), 15)
indicesC <- sample(as.integer(setdiff(instancia, indicesA + indicesB)), 13)

muestraA <- tiempos$algA[indicesA]
muestraB <- tiempos$algC[indicesB]
muestraC <- tiempos$algC[indicesC]

# Crear los gráficos Q-Q plot
qqplot_A <- ggqqplot(muestraA, main="A")
qqplot_B <- ggqqplot(muestraB, main="B")
qqplot_C <- ggqqplot(muestraC, main="C")

# Organizar los gráficos en una sola fila
grid.arrange(qqplot_A, qqplot_B, qqplot_C, nrow=1)

```

Como se puede apreciar,los gráficos poseen valores atípicos, por lo que no se cumple la condición de la distribución normal del procedimiento ANOVA. En consecuencia, se hará uso de una prueba no paramétrica con variables numéricas. Como se está trabajando con más de dos muestras independientes, se utilizará la prueba de Kruskal-Wallis. Además, los tamaños de las muestras difieren.

Para trabajar con la prueba de Kruskal-Wallis, se deben verificar las siguientes condiciones:

1- La variable independiente debe tener a lo menos dos niveles.
2- La escala de la variable dependiente debe ser, a lo menos, ordinal.
3- Las observaciones son independientes entre sí.

La primera condición se cumple, puesto que la variable independiente tiene a lo menos dos niveles (versiones A, B y C del algoritmo), de hecho tiene 3 niveles.

Como se está trabajando con mediciones de tiempo en milisegundos, se puede afirmar que la escala de medición es a lo menos ordinal, como bien se explicó con anterioridad.

La tercera condición se cumple, puesto que las observaciones son independientes entre sí.

Ahora, se procede a trabajar con la prueba de Kruskal-Wallis.

```{r}
alfa <- 0.05

# Para efectos de la prueba, se transforma a formato largo
Algoritmo <- factor(c(rep("muestraA", length(muestraA)),
               rep("muestraB", length(muestraB)),
               rep("muestraC", length(muestraC))))
Tiempo <- c(muestraA, muestraB, muestraC)

info <- data.frame(Tiempo, Algoritmo)

# Hacer la prueba de Kruskal - Wallis .
prueba <- kruskal.test( Tiempo ~ Algoritmo , data = tiempos )
print(prueba)
```

Como el p-value es mayor al nivel de significancia establecido, se falla al rechazar la hipótesis nula. Por lo tanto, con un 95% de confianza, se puede inferir que no hay prueba suficiente para respaldar la intuición de la memorista.

### **Pregunta 4**
**La memorista también sospecha que, al comparar las mismas instancias con iguales características, las mejores soluciones encontradas por las diferentes versiones del algoritmo tienen rendimientos distintos. ¿Estará en lo cierto? Para responder, filtren los datos para tener las instancias con 50 o más nodos y seleccionen las columnas con los mejores rendimientos registrados. Usando como semilla el valor 71, obtengan una muestra aleatoria de 22 instancias. Lleven los datos a formato largo y utilicen una prueba no paramétrica apropiada para analizar los datos obtenidos. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.**

Hipótesis:

- H0: Para las mismas instancias no existe diferencia significativa en el rendimiento de la mejores soluciones encontradas para las versiones A, B y C del algoritmo cuando las instancias tienen 50 o más nodos, es decir, poseen rendimientos similares.

- HA: Para las mismas instancias existe diferencia significativa en el rendimiento de la mejores soluciones encontradas para las versiones A, B y C del algoritmo cuando las instancias tienen 50 o más nodos, es decir, al menos uno de los algoritmos obtiene un rendimiento distinto al de los demás.

```{r}
instancia <- 1:170
algA <- datos$mejor.A[datos$n.nodos >= 50]
algB <- datos$mejor.B[datos$n.nodos >= 50]
algC <- datos$mejor.C[datos$n.nodos >= 50]

tiempos <- data.frame(instancia, algA, algB, algC)

set.seed(71)

indices <- sample(instancia, 22)

muestraMejorA <- as.double(tiempos$algA[indices])
muestraMejorB <- as.double(tiempos$algB[indices])
muestraMejorC <- as.double(tiempos$algC[indices])

# Crear los gráficos Q-Q plot
qqplot_A <- ggqqplot(muestraMejorA, main="A")
qqplot_B <- ggqqplot(muestraMejorB, main="B")
qqplot_C <- ggqqplot(muestraMejorC, main="C")

# Organizar los gráficos en una sola fila
grid.arrange(qqplot_A, qqplot_B, qqplot_C, nrow=1)

# No se cumple normalidad en ninguno de los grupos

Algoritmo <- factor(c(rep("muestraMejorA", length(muestraMejorA)),
               rep("muestraMejorB", length(muestraMejorB)),
               rep("muestraMejorC", length(muestraMejorC))))
Tiempo <- c(muestraMejorA, muestraMejorB, muestraMejorC)

info <- data.frame(Tiempo, Algoritmo)

```

Como se puede apreciar,los gráficos poseen valores atípicos, por lo que no se cumple la condición de la distribución normal del procedimiento ANOVA. En consecuencia, se hará uso de una prueba no paramétrica con variables numéricas. Como se está trabajando con más de dos muestras correlacionadas, se utilizará la prueba de Friedman.

Para trabajar con la prueba de Friedman., se deben verificar las siguientes condiciones:

1- La variable independiente debe ser categórica y tener a lo menos tres niveles.
2- La escala de la variable dependiente debe ser, a lo menos, ordinal.
3- Los sujetos son una muestra aleatoria e independiente de la población.

La variable independiente se considera categórica y tiene más de dos niveles porque representa diferentes categorías o grupos distintos que no pueden ser clasificados de manera numérica continua. En este caso, los niveles de la variable son A, B y C, que son etiquetas o nombres que identifican las categorías específicas.

Para la segunda condición, como se está trabajando con mediciones de porcentajes, se puede afirmar que la escala de medición es a lo menos ordinal, ya que los valores se pueden ordenar y es lógico establecer relaciones de orden. Esto se debe a que se puede comparar los valores y determinar que, por ejemplo, 10% es menor que 90%.

Los sujetos con los que trabaja corresponden a una muestra aleatoria e independiente de la población, por lo que se cumple la tercera condición.

Ahora, se procede a trabajar con la prueba de Friedman.

```{r}
# Establecer nivel de significaci ó n
alfa <- 0.05

Sujeto <- rep(1:22, 3)
# Hacer la prueba de Friedman .
prueba <- friedman.test( Tiempo ~ Algoritmo | Sujeto , data = info )
print(prueba)
```

Puesto que el p-value es inferior al nivel de significancia establecido, se rechaza la hipótesis nula a favor de la hipótesis alternativa. Por lo tanto, con un 95% de confianza, se puede inferir que las mejores soluciones encontradas por las versiones A, B y C tienen rendimientos distintos.

Lo anterior implica que se encontraron diferencias significativas, por lo que se procederá a realizar un procedimiento post-hoc.

```{r}
post_hoc <- pairwise.wilcox.test(info$Tiempo,
                                 info$Algoritmo,
                                 p.adjust.method = "holm",
                                 paired = TRUE)

print(post_hoc)
```

Luego de realizar el procedimiento post-hoc se obtuvo un p-value < al nivel de significancia, el cual permite determinar que existe una diferencia significativa en los rendimientos de la mejores soluciones encontradas entre las versiones A y B del algoritmo, esto cuando las instancias tienen 50 o más nodos.



*************************************

Ejemplo de solución ejercicio prático N°7
Pruebas no paramétricas para variables numéricas
Enunciado
En el trabajo de título de una estudiante del DIINF se reportan tiempos de ejecución (en milisegundos) y la cercanía con la solución óptima (en por ciento) de la mejor solución encontrada con tres versiones de un algoritmo genético para resolver instancias del problema del vendedor viajero disponibles en repositorios públicos. Ahora debe enfrentar el análisis de estos datos, por que está solicitando ayuda de las y los estudiantes de Estadística Inferencial.

Obtengamos los datos en formato ancho.
```{r}
src_dir <- "~/Downloads"
src_basename <- "EP07 Datos.csv"
src_file <- file.path(src_dir, src_basename)
print(src_file)
## [1] "~/Downloads/EP07 Datos.csv"
datos <- read.csv(file = src_file, stringsAsFactors = TRUE)
```

Pregunta 1
Observando los datos, la memorista sospecha que hay diferencias significativas en el tiempo de ejecución entre las versiones A y C del algoritmo cuando las instancias tienen 100 o más nodos. ¿Los datos respaldan la intuición de la memorista?

Para responder, filtren los datos para tener las instancias con 100 o más nodos y seleccionen las columnas de los tiempos de ejecución de las versiones A y C en formato ancho. Usando como semilla el valor 213, obtengan muestras aleatorias independientes de 20 tiempos registrados por la versión A y 18 tiempos registrados por la versión C del algoritmo. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.

Primero, filtramos para quedarnos con las instancias que nos interesan y quitar las columnas que no necesitamos.
```{r}
nA <- 20
nB <- 30

set.seed(213)
dw1 <- datos %>%
  filter(n.nodos >= 100) %>%
  select(instancia, tiempo.A, tiempo.C) %>%
  sample_n(nA + nB)

dl1 <- data.frame(
  instancia = dw1[["instancia"]],
  algoritmo = c(rep("A", nA), rep("C", nB)),
  tiempo = c(dw1[["tiempo.A"]][1:nA],
             dw1[["tiempo.C"]][(nA+1):(nA+nB)])
)
dl1[["instancia"]] <- factor(dl1[["instancia"]])
dl1[["algoritmo"]] <- factor(dl1[["algoritmo"]])
Como es aconsejado, echemos un vistazo a los datos que se están trabajando.

p1 <- gghistogram(
  dl1,
  x = "tiempo",
  xlab = "algoritmo",
  color = "algoritmo", fill = "algoritmo",
  bins = 5
)
p1 <- p1 + facet_grid(~ algoritmo)
print(p1)
```

Podemos ver que las muestras no parecen tomadas desde una distribución normal, lo que podemos confirmar con pruebas auxiliares de normalidad.
```{r}
tiempo.A <- dw1[["tiempo.A"]][1:20]
tiempo.C <- dw1[["tiempo.C"]][21:38]
print(shapiro.test(tiempo.A))
```

## 
##  Shapiro-Wilk normality test
## 
## data:  tiempo.A
## W = 0.94634, p-value = 0.3149
print(shapiro.test(tiempo.C))
## 
##  Shapiro-Wilk normality test
## 
## data:  tiempo.C
## W = 0.79917, p-value = 0.001478
Se confirma que los tiempos exhibidos por la versión C están lejos de seguir una distribución normal. Corresponde entonces usar una prueba no paramétrica para analizar estos datos. En este caso, una prueba de Wilcoxon-Mann-Whitney, en reemplazo de una prueba T de Student para muestras independientes, con las siguientes hipótesis:

H0: no hay diferencia en los tiempos de ejecución requeridos por ambos algoritmos para instancias con 100 o más nodos (se distribuyen de igual forma).

HA: sí hay diferencias en los tiempos de ejecución requeridos por ambos algoritmos para instancias con 100 o más nodos (distribuciones distintas).

Verifiquemos que se cumplen las condiciones para aplicar esta prueba no paramétrica con validez:

Las observaciones de ambas muestras son independientes. De como hicimos el muestreo más arriba, podemos asegurar que las muestras fueron escogidas de forma aleatoria y no comparten alguna instancia.
La escala de medición empleada debe ser a lo menos ordinal. Como la variable en estudio es de tiempo, que corresponde a una medición física, la escala de la medición cumple con condiciones más exigente que solo la ordinal, y tiene sentido hablar de “más/igual/menos tiempo”.
Como se cumplen bien las condiciones, usemos el típico nivel de significación α=0,05

Procedamos entonces a realizar la prueba.
```{r}
prueba1 <- wilcox.test(tiempo.A, tiempo.C, paired = FALSE)
print(prueba1)
```
## 
##  Wilcoxon rank sum exact test
## 
## data:  tiempo.A and tiempo.C
## W = 310, p-value = 6.053e-05
## alternative hypothesis: true location shift is not equal to 0
Podemos concluir, entonces, que existe fuerte evidencia en contra de la hipótesis nula (W=310,p<0,001), por lo que la rechazamos en favor de la alternativa. Esto es, los algoritmos no tardan tiempos similares en resolver instancias con 100 o más nodos del problema del vendedor viajero. Mirando los histogramas de los datos, podemos sugerir que el algoritmo C requiere, en promedio, significativamente menos tiempo de procesamiento.

Pregunta 2
La memorista también sospecha que, al comparar las mismas instancias con 70 a 85 nodos, las mejores soluciones encontradas por las versiones B y C tienen rendimientos distintos. ¿Estará en lo cierto?

Para responder, filtren los datos para tener las instancias que tengan de 70 a 85 nodos y seleccionen las columnas con el mejor rendimiento de las versiones B y C en formato ancho. Usando como semilla el valor 117, obtengan una muestra aleatoria de 24 instancias. Lleven los datos a formato largo y utilicen una prueba no paramétrica apropiada para analizar las muestras obtenidas.

Obtenemos la muestra de datos en formato ancho. Como tenemos que comparar los resultados obtenidos por los algoritmos con las mismas instancias, debemos obtener una muestra apareada de 24 observaciones.
```{r}
set.seed(117)
dw2 <- datos %>%
  filter(n.nodos >= 70 & n.nodos <= 85) %>%
  select(instancia, mejor.B, mejor.C) %>%
  sample_n(24)
Llevamos los datos a formato largo

dl2 <- dw2 %>%
  pivot_longer(
    cols = c("mejor.B", "mejor.C"),
    names_to = "algoritmo",
    values_to = "resultado"
  )
dl2[["instancia"]] <- factor(dl2[["instancia"]])
dl2[["algoritmo"]] <- factor(dl2[["algoritmo"]])
Revisemos los datos con un diagrama de cajas

p2 <- ggboxplot(
  data = dl2,
  x = "algoritmo", y = "resultado",
  xlab = "algoritmo",
  color = "algoritmo"
)
print(p2)
```

Vemos que los datos para el algoritmo B presentan una leve asimetría y la presencia de valores atípicos. Sería prudente utilizar una prueba no paramétrica para el análisis, como alternativa a una prueba T de Student para muestras apareadas, que en este caso correspondería a una prueba de rangos con signo de Wilcoxon, con las siguientes hipótesis:

H0: no hay diferencia en las mejores soluciones encontradas por las versiones B y C del algoritmo en las mismas instancias con 70 a 85 nodos (se distribuyen de igual forma).

HA: sí hay diferencias en las mejores soluciones obtenidas por ambas versiones del algoritmo en las mismas instancias con 70 a 85 nodos (distribuciones distintas).

Verifiquemos las condiciones:

Los pares de observaciones son independientes. Efectivamente, si el experimento fue realizado correctamente por la memorista, cómo se desempeña un algoritmo no debería tener influencia en cómo rinde el segundo.
La escala de medición empleada para ambas muestras debe ser a lo menos ordinal. Valores porcentuales cumplen esta condición, pues podemos compararlos y ordenarlos.
La escala de medición empleada para las observaciones es intrínsecamente continua. Al tratarse de valores porcentuales, en teoría estas mediciones podrían tener un número indeterminado de decimales, por lo que cumpliría con esta condición.
Procedamos con la prueba no paramétrica, ya que se cumplen todas las condiciones.
```{r}
prueba2 <- wilcox.test(
  x = dw2[["mejor.B"]],
  y = dw2[["mejor.C"]],
  paired = TRUE
)
cat("Prueba de rangos con signo de Wilcoxon\n")
## Prueba de rangos con signo de Wilcoxon
print(prueba2)
``` 

## 
##  Wilcoxon signed rank exact test
## 
## data:  dw2[["mejor.B"]] and dw2[["mejor.C"]]
## V = 167, p-value = 0.6431
## alternative hypothesis: true location shift is not equal to 0
El resultado de la prueba indica que no hay suficiente evidencia (V=167,p=0,643) para descartar la hipótesis nula en favor de la alternativa. Así, pareciera que el algoritmo B consigue resultados similares a los que se obtienen con el algoritmo C en las mismas instancias con 70 a 85 nodos.

Pregunta 3
La memorista además cree que hay diferencias significativas en el tiempo de ejecución entre las versiones del algoritmo cuando las instancias de prueba tienen 100 o más nodos. ¿Los datos respaldan la intuición de la memorista?

Para responder, filtren los datos para tener las instancias con 100 o más nodos y seleccionen las columnas con los tiempos de ejecución registrados (en formato ancho). Usando como semilla el valor 33, obtengan muestras aleatorias independientes de 12, 13 y 14 tiempos registrados por las versiones A, B y C, respectivamente. Lleven los datos a formato largo y utilicen una prueba no paramétrica para analizar las muestras obtenidas.



Primero, filtramos para quedarnos con las instancias que nos interesan y quitar las columnas que no necesitamos.

```{r}
dw3 <- datos %>%
  filter(n.nodos >= 100) %>%
  select(instancia, tiempo.A, tiempo.B, tiempo.C)
```
Ahora tomamos la muestra solicitada.
```{r}
nA <- 12; nB <- 13; nC <- 14
nI <- nA + nB + nC
```
Es importante que lo hagamos con una sola llamada a la función sample(), para evitar que los algoritmos compartan alguna instancia, asegurando así muestras independientes.
```{r}
set.seed(33)
i <- sample(1:nrow(dw3), nI)
seleccion <- dw3[i, ]
tiempo.A <- seleccion[["tiempo.A"]][1:nA]
tiempo.B <- seleccion[["tiempo.B"]][(nA+1):(nA+nB)]
tiempo.C <- seleccion[["tiempo.C"]][(nA+nB+1):nI]
```
Creamos una versión larga de los datos.
```{r}
dl3 <- data.frame(
  instancia = seleccion[["instancia"]],
  algoritmo = c(rep("A", nA), rep("B", nB), rep("C", nC)),
  tiempo = c(tiempo.A, tiempo.B, tiempo.C)
)
dl3[["instancia"]] <- factor(dl3[["instancia"]])
dl3[["algoritmo"]] <- factor(dl3[["algoritmo"]])

```

Puesto que cada muestra contiene instancias de prueba distintas, la primera alternativa sería usar ANOVA de una vía para muestras independientes para este análisis. Esta prueba permitiría determinar si la memorista tiene o no razón en pensar que existen diferencias significativas en los tiempos medios de ejecución de los algoritmos.

Verificamos las condiciones:

Existe independencia entre las muestras, pues no hay elementos en común y el tiempo que tarda un algoritmo en alguna de las instancias escogida no debería influir en el tiempo que tarda otro algoritmo en otra instancia.
También se cumple que la variable dependiente tiene una escala de intervalos iguales, pues es una medición física (tiempo).
Veamos si se cumple con las condiciones de normalidad y homocedasticidad por medio de histogramas.
```{r}
p3 <- gghistogram(
  dl3,
  x = "tiempo",
  xlab = "algoritmo",
  color = "algoritmo", fill = "algoritmo",
  bins = 10
)
p3 <- p3 + facet_grid(~ algoritmo)
print(p3)
```

Podemos ver que las muestras no siguen un comportamiento aproximadamente normal, por lo que no podríamos suponer razonablemente que las poblaciones de donde provienen sí tengan dicha distribución.
Como el problema no parece requerir un valor de las medias estudiadas, sería conveniente bajar las exigencias y optar por una prueba no paramétrica, como se nos indica en el enunciado. En este caso, correspondería una prueba de Kruskal-Wallis.
Mirando el gráfico, no podríamos suponer tampoco que las formas de las distribuciones subyacentes sean iguales, por lo que las hipótesis no podrían referirse a medianas. Así, las hipótesis no paramétricas a contrastar serían:

H0: Los tiempos promedios que tardan los algoritmos en resolver las instancias con 100 o más nodos son similares.

HA: al menos uno de los algoritmos exhibe tiempos promedios significativamente distintos a uno de los otros dos algoritmos para resolver las instancias con 100 o más nodos.

Verifiquemos las condiciones:

Ya sabemos que existe independencia ente las observaciones.
También se verifica que la variable independiente tiene más de dos niveles (algoritmos A, B y C).
Por último, la escala de la variable dependiente debe ser al menos ordinal, y sabemos que las mediciones físicas cumplen de sobra con tal condición.
Aplicamos la prueba, con el nivel de significación más común.

```{r}
alfa <- 0.05
prueba3 <- kruskal.test(tiempo ~ algoritmo, data = dl3)
print(prueba3)
```
## 
##  Kruskal-Wallis rank sum test
## 
## data:  tiempo by algoritmo
## Kruskal-Wallis chi-squared = 19.802, df = 2, p-value = 5.012e-05
La prueba indica que hay suficiente evidencia para rechazar H0 en favor de HA (χ2=19,8;p<0,001). En consecuencia, podemos concluir con 95% de confianza que los algoritmos difieren significativamente en el tiempo que tardan en resolver las instancias del problema del vendedor viajero con 100 o más nodos.

Como la prueba ómnibus de Kruskal-Wallis detecta diferencias, debemos hacer ahora un procedimiento post-hoc. Para ello usaremos múltiples pruebas de Wilcoxon-Mann-Whitney entre pares de grupos, aplicando el ajuste de Benjamini & Hochberg (1995) por tener mayor poder estadístico que varios otros métodos.
```{r}
posthoc1 <- pairwise.wilcox.test(
  dl3[["tiempo"]],
  dl3[["algoritmo"]],
  p.adjust.method = "BH",
  paired = FALSE
)
print(posthoc1)
```
## 
##  Pairwise comparisons using Wilcoxon rank sum exact test 
## 
## data:  dl3[["tiempo"]] and dl3[["algoritmo"]] 
## 
##   A       B      
## B 0.64951 -      
## C 0.00037 1.3e-05
## 
## P value adjustment method: BH
El procedimiento post-hoc no encuentra diferencias significativas entre los algoritmos A y B (p=0,650), pero estos dos algoritmos parecen tardar, en promedio, significativamente más que el algoritmo C (p<0,001) en resolver las instancias del problema del vendedor viajero con 100 o más nodos.

Pregunta 4
La memorista también intuye que, al comparar las mismas instancias de prueba con 100 o más nodos, las mejores soluciones encontradas por las diferentes versiones del algoritmo tienen rendimientos distintos. ¿Estará en lo cierto?

Para responder, filtren los datos para tener las instancias con 100 o más nodos y seleccionen las columnas con los mejores rendimientos registrados. Usando como semilla el valor 33, obtengan una muestra aleatoria de 26 instancias. Lleven los datos a formato largo y utilicen una prueba no paramétrica apropiada para analizar los datos obtenidos.

Obtenemos la muestra de datos en formato ancho. Como tenemos que comparar los resultados obtenidos por los algoritmos con las mismas instancias, debemos obtener una muestra apareada de 26 observaciones.
```{r}
nD <- 26
set.seed(33)
dw4 <- datos %>%
  filter(n.nodos >= 100) %>%
  select(instancia, mejor.A, mejor.B, mejor.C) %>%
  sample_n(nD)
```
Llevamos los datos a formato largo
```{r}
dl4 <- dw4 %>%
  pivot_longer(
    cols = c("mejor.A", "mejor.B", "mejor.C"),
    names_to = "algoritmo",
    values_to = "resultado"
  )
dl4[["instancia"]] <- factor(dl4[["instancia"]])
dl4[["algoritmo"]] <- factor(dl4[["algoritmo"]])
```

Puesto que cada muestra contiene la calidad de la solución obtenida por cada algoritmo al resolver las mismas instancias de prueba, correspondería usar ANOVA de una vía para medidas repetidas, que permitiría determinar si la memorista tiene o no razón en pensar que existen diferencias significativas entre los diferentes algoritmos.

Revisemos los datos con un diagrama de cajas.
```{r}
p4 <- ggboxplot(
  dl4,
  x = "algoritmo", y = "resultado",
  xlab = "algoritmo",
  color = "algoritmo"
)
print(p4)
```

Vemos que existe algunos valores atípicos en los datos, además de ciertas asimetrías. Luego, preferimos usar una prueba no paramétrica, como nos instruye el enunciado. Al tratarse de medidas repetidas y más de dos grupos, corresponde usar la prueba de Friedman.

Verificamos las condiciones:

La variable independiente es categórica y tiene a lo menos tres niveles: mejor.A, mejor.By mejor.C.
Las tripletas de observaciones son independientes pues, si el experimento fue realizado correctamente, el desempeño de un algoritmo no debería tener influencia en el rendimiento que alcancen los otros dos.
La escala de la variable dependiente es a lo menos ordinal, pues valores porcentuales se pueden comparar y ordenar.
En consecuencia, se cumplen las condiciones para aplicar la prueba de Friedman, con las siguientes hipótesis no paramétricas:

H0: la calidad de las mejores soluciones conseguidas para las mismas instancias de prueba con 100 o más nodos por los tres algoritmos se distribuyen de forma similar.

HA: al menos uno de los algoritmos entrega mejores soluciones con calidad significativamente distinta que los otros dos al resolver las mismas instancias del problema del vendedor viajero con 100 o más nodos.

Aplicamos la prueba con un nivel de significación exigente por la presencia de valores atípicos (α=0,01).
```{r}
prueba4 <- friedman.test(
  resultado ~ algoritmo | instancia,
  data = dl4
)
print(prueba4)
```
## 
##  Friedman rank sum test
## 
## data:  resultado and algoritmo and instancia
## Friedman chi-squared = 21.689, df = 2, p-value = 1.951e-05
La prueba indica que hay suficiente evidencia (χ2=21,7;p<0,001
) para rechazar la hipótesis nula en favor de la alternativa. En consecuencia, podemos concluir con 99% de confianza que al menos uno de los algoritmo tiene un rendimiento distinto a alguno de los otros o a ambos.

Puesto que la prueba ómnibus (de Friedman) detecta diferencias, debemos hacer ahora un procedimiento post-hoc usando múltiples pruebas de rangos con signo de Wilcoxon entre pares de grupos y, al igual que en la pregunta anterior, aplicando el ajuste de Benjamini & Hochberg (1995).
```{r}
posthoc2 <- pairwise.wilcox.test(
  dl4[["resultado"]],
  dl4[["algoritmo"]],
  p.adjust.method = "BH",
  paired = TRUE
)
## Warning in wilcox.test.default(xi, xj, paired = paired, ...): cannot compute
## exact p-value with zeroes
print(posthoc2)
```
## 
##  Pairwise comparisons using Wilcoxon signed rank exact test 
## 
## data:  dl4[["resultado"]] and dl4[["algoritmo"]] 
## 
##         mejor.A mejor.B
## mejor.B 2.2e-06 -      
## mejor.C 0.0025  0.0382 
## 
## P value adjustment method: BH
Por ahora vamos a ignorar el warning que nos da la función, puesto que sabemos que si hay empates, el algoritmo interno de esta prueba los descarta antes del cálculo de los rangos (rankings). Si fuéramos muy rigorosos, deberíamos revisar que no son tantos empates en cada caso. Si esto es así, los p-valores que se obtienen son buenas aproximaciones de los exactos.

Expresemos la conclusión.

Con 99% confianza, el procedimiento post-hoc no encuentra diferencias significativas entre los algoritmos B y C (p>0,038), pero estos dos algoritmos parecen obtener, en promedio, significativamente peores soluciones (más lejanas a la solución óptima) que las que consigue el algoritmo A (p<0,003).